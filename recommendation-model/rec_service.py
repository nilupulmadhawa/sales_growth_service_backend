# -*- coding: utf-8 -*-
"""rec service.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u_8CzKA6C_yPKsTSeH_i_1iokAh3Z9VB
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install lightfm

import pandas as pd
import numpy as np
from lightfm import LightFM
from lightfm.data import Dataset
from lightfm.evaluation import precision_at_k, auc_score, reciprocal_rank
from lightfm.cross_validation import random_train_test_split
import matplotlib.pyplot as plt
import joblib

# Load your data
users_df = pd.read_csv('/content/drive/MyDrive/recommendation_service_dataset/users.csv')
products_df = pd.read_csv('/content/drive/MyDrive/recommendation_service_dataset/products.csv')
events_df = pd.read_csv('/content/drive/MyDrive/recommendation_service_dataset/events.csv')

# Preprocessing
events_df['product_id'] = events_df.apply(lambda row: int(row['uri'].split('/')[-1]) if '/product/' in row['uri'] else np.nan, axis=1)

events_df = events_df.dropna(subset=['product_id', 'user_id'])

events_df.loc[:, 'user_id'] = events_df['user_id'].astype(int)
events_df.loc[:, 'product_id'] = events_df['product_id'].astype(int)

filtered_events = events_df[events_df['user_id'].isin(users_df['id']) & events_df['product_id'].isin(products_df['id'])]

# Add age group feature to users
users_df['age_group'] = pd.cut(users_df['age'], bins=[0, 18, 25, 35, 45, 55, 65, 100], labels=['0-18', '19-25', '26-35', '36-45', '46-55', '56-65', '65+'])


print(filtered_events.head())
print(users_df.head())

# Prepare the dataset
dataset = Dataset()
dataset.fit(
    users=(x for x in users_df['id']),
    items=(x for x in products_df['id']),
    user_features=(f"{row['gender']}_{row['age_group']}_{row['state']}" for index, row in users_df.iterrows()),
    item_features=(f"{row['category']}_{row['brand']}" for index, row in products_df.iterrows())
)

(interactions_matrix, weights_matrix) = dataset.build_interactions(
    (row['user_id'], row['product_id']) for index, row in filtered_events.iterrows()
)

user_features = dataset.build_user_features(
    (row['id'], [f"{row['gender']}_{row['age_group']}_{row['state']}"])
    for index, row in users_df[users_df['id'].isin(filtered_events['user_id'])].iterrows()
)

item_features = dataset.build_item_features(
    (row['id'], [f"{row['category']}_{row['brand']}"])
    for index, row in products_df[products_df['id'].isin(filtered_events['product_id'])].iterrows()
)

import matplotlib.pyplot as plt

# Assuming 'filtered_events' is your final events DataFrame after preprocessing
# Interactions per User
user_interactions = filtered_events.groupby('user_id').size()
item_interactions = filtered_events.groupby('product_id').size()

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
user_interactions.hist(bins=30, edgecolor='black')
plt.title('Interactions per User')
plt.xlabel('Number of Interactions')
plt.ylabel('Number of Users')

plt.subplot(1, 2, 2)
item_interactions.hist(bins=30, edgecolor='black')
plt.title('Interactions per Item')
plt.xlabel('Number of Interactions')
plt.ylabel('Number of Items')

plt.tight_layout()
plt.show()

# Split the data into training and testing sets
train, test = random_train_test_split(interactions_matrix, test_percentage=0.2, random_state=np.random.RandomState(42))

# Initialize the LightFM model with WARP loss function
model = LightFM(loss='warp', no_components=30, user_alpha=1e-4, item_alpha=1e-4)

from lightfm.evaluation import reciprocal_rank

# Train the model with less frequent evaluations
num_epochs = 50
evaluation_interval = 5  # Evaluate every 5 epochs
for epoch in range(num_epochs):
    model.fit_partial(train, user_features=user_features, item_features=item_features, epochs=1)

    if (epoch + 1) % evaluation_interval == 0:
        train_rr = reciprocal_rank(model, train, user_features=user_features, item_features=item_features).mean()
        test_rr = reciprocal_rank(model, test, user_features=user_features, item_features=item_features).mean()
        print(f'Epoch: {epoch+1} - Train Reciprocal Rank: {train_rr:.4f}, Test Reciprocal Rank: {test_rr:.4f}')

# Final evaluation at the end of training
train_precision = precision_at_k(model, train, k=10, user_features=user_features, item_features=item_features).mean()
test_precision = precision_at_k(model, test, k=10, user_features=user_features, item_features=item_features).mean()
train_auc = auc_score(model, train, user_features=user_features, item_features=item_features).mean()
test_auc = auc_score(model, test, user_features=user_features, item_features=item_features).mean()

print('Final evaluation results:')
print(f'Precision: Train {train_precision:.4f}, Test {test_precision:.4f}')
print(f'AUC: Train {train_auc:.4f}, Test {test_auc:.4f}')

# Sample recommendation function
def sample_recommendation(model, user_id, user_features, item_features, dataset, num_items=10):
    n_users, n_items = dataset.interactions_shape()
    user_x = dataset.mapping()[0][user_id]
    scores = model.predict(user_x, np.arange(n_items), user_features=user_features, item_features=item_features)
    top_items = np.argsort(-scores)[:num_items]

    return [dataset.mapping()[2][i] for i in top_items]

# Test the recommendation function for a specific user 17033
user_id = 17033
recommended_products = sample_recommendation(model, user_id, user_features, item_features, dataset)
print(f'Recommended product IDs for user {user_id}: {recommended_products}')

joblib.dump(model, 'recommendation_hybrid_model.pkl')